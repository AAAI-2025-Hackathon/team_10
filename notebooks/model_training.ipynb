{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize path to data folder\n",
    "base_data_path = \"path_to_folder_to_store_data\"\n",
    "\n",
    "# Create 2 new directories to store train images and their labels\n",
    "imagesTr_path = os.path.join(base_data_path, \"imagesTr\")\n",
    "labelsTr_path = os.path.join(base_data_path, \"labelsTr\")\n",
    "\n",
    "os.makedirs(imagesTr_path, exist_ok=True)\n",
    "os.makedirs(labelsTr_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download IDEAS [Dataset](https://openneuro.org/datasets/ds005602/versions/1.0.0) from OpenNeuro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_data_folder = \"path_to_the_downloaded_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon analysis, it is found that there are some masks missing in the data set. Also, there are no masks for healthy patients. We need to create them manually. Kindly read the information the [dataset](https://openneuro.org/datasets/ds005602/versions/1.0.0) page for more information, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_masks = [12, 115, 261, 269, 326, 331, 353, 368, 437, 122, 242]\n",
    "\n",
    "def copy_and_rename_input_images(data_folder, imagesTr_path, missing_masks):\n",
    "    \"\"\"Function to read T1w from respective directory and rename to comply with nnUNet format\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Path to the downloaded original dataset folder\n",
    "        imagesTr_path (str): Path to store renamed input images\n",
    "        missing_masks (List): Python list contains ids of missing masks \n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        print(dirs)\n",
    "        for file in files:\n",
    "            if file.endswith('T1w.nii') or file.endswith('T1w.nii.gz'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                ids = re.findall(r'-(\\d+)', file) # extract only id from the name\n",
    "                if (len(ids[0]) < 4) and (int(ids[0]) not in missing_masks): # filter out healthy patients images \n",
    "                    shutil.copy(file_path, os.path.join(imagesTr_path, f\"patient_{ids[0]}_0000.nii.gz\"))\n",
    "    print(\"Copying and renaming of input images done\")               \n",
    "\n",
    "copy_and_rename_input_images(downloaded_data_folder, imagesTr_path, missing_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_mask_folder = \"Path_to_downloaded_masks\"\n",
    "\n",
    "def copy_and_rename_mask_files(mask_folder, labelsTr_path):\n",
    "    \"\"\"Function to read raw masks from respective directory and rename to comply with nnUNet format\n",
    "\n",
    "    Args:\n",
    "        mask_folder (str): Path to the downloaded original masks folder\n",
    "        labelsTr_path (str): Path to store renamed input masks\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(mask_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('MaskInRawData.nii') or file.endswith('MaskInRawData.nii.gz'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                id = re.findall(r'(\\d+)_', file) # extract only id from the name\n",
    "                shutil.copy(file_path, os.path.join(labelsTr_path, f\"patient_{id[0]}.nii.gz\"))\n",
    "    print(\"Copying and renaming of masks done\")\n",
    "\n",
    "copy_and_rename_mask_files(downloaded_mask_folder, labelsTr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create masks for the healthy patients. There are 100 healthy patient's MRI images but there are no labels avaialable. The healthy patients IDs have 4 digits and starts from 4001. Generate masks for these images using a python scripts found under epilepsydetection folder in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_patients_mask = \"path_to_newly_generated_mask\" \n",
    "\n",
    "def copy_and_rename_healthy_mask_files(healthy_patients_mask, labelsTr_path):\n",
    "    \"\"\"Function to read newly created masks for healthy patients from respective directory and rename to comply with nnUNet format\n",
    "    \n",
    "    Args:\n",
    "        healthy_patients_mask (str): Path to the newly created masks\n",
    "        labelsTr_path (_type_): Path to store renamed input masks\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(healthy_patients_mask):\n",
    "        for file in files:\n",
    "            if file.endswith('MaskInOrig.nii') or file.endswith('MaskInOrig.nii.gz'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, file)                       \n",
    "                ids = re.findall(r'(\\d+)_', file) # extract only id from the name\n",
    "                if (len(ids[0]) == 4):           \n",
    "                    shutil.copy(file_path, os.path.join(labelsTr_path, f\"patient_{ids[0]}.nii.gz\"))\n",
    "    print(\"Copying and renaming of masks done\")   \n",
    "\n",
    "copy_and_rename_healthy_mask_files(healthy_patients_mask, labelsTr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Fully Automated & Adaptable__  <p style=\"font-size:14px; font-family:Arial;\"> nnU-Net auto-configures preprocessing, architecture, and training for any medical image segmentation task. Robust again different dimensions </p>\n",
    "* __State-of-the-Art Performance__  <p style=\"font-size:14px; font-family:Arial;\"> Outperforms most models in segmentation benchmarks (BraTS, MSD, KiTS) without manual tuning. </p>\n",
    "* __Plug & Play Simplicity__  <p style=\"font-size:14px; font-family:Arial;\"> Just organize your dataset, train, and get top-tier results with multi-GPU support.</p>\n",
    "\n",
    "\n",
    "Follow the steps in the official [documentation](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md) to setup the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a virutal python environment \n",
    "python -m venv venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"font-size:14px; font-family:Arial;\"> Install <a href=https://pytorch.org/get-started/locally// > PyTorch </a> as described on their website (conda/pip). Please install the latest version with support for your hardware (cuda, mps, cpu). <br>\n",
    " DO NOT JUST pip install nnunetv2 WITHOUT PROPERLY INSTALLING PYTORCH FIRST. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install as integrative framework \n",
    "git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
    "cd nnUNet\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14px; font-family:Arial;\"> nnUNet requires specific folder structure as shown <a href=\"https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md\">here</a>. Create them first. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir nnUNetraw\n",
    "mkdir nnUNetpreprocessed\n",
    "mkdir nnUNetresults\n",
    "\n",
    "cd nnUNetraw\n",
    "mkdir Dataset001_BrainEpilepsy # each dataset names DatasetXXX_YYY where XXX is a 3-digit identifier (such as 001, 002, 043, 999, ...) and YYY is the (unique) dataset name.\n",
    "\n",
    "# Move the train and label data into the dataset folder\n",
    "mv imagesTr Dataset001_BrainEpilepsy/\n",
    "mv labelsTr Dataset001_BrainEpilepsy/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14px; font-family:Arial;\">Setup the environment variables properly. For reference, check the documentation <a href=https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md>here.</a><br>\n",
    "You can permanently set paths by locating the .bashrc file in your home folder, open it and add the following lines to the bottom of the file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export nnUNet_raw=\"/media/fabian/nnUNet_raw\"\n",
    "export nnUNet_preprocessed=\"/media/fabian/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/media/fabian/nnUNet_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14px; font-family:Arial;\">Once the paths are set correctly, we need to preprocess the dataset to check whether it is suitable to train it with nnUNet model.<br> The easiest way to run fingerprint extraction, experiment planning and preprocessing is by running the below command in the terminal <br><br> <em>nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity </em> <br><br>Where DATASET_ID is the dataset id of your dataset. For example, 001 in our case, so <br> <br><em> nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity</em> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:14px; font-family:Arial;\">Training models is done with the nnUNetv2_train command. The general structure of the command is:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD [additional options, see -h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DATASET_NAME_OR_ID <p style=\"font-size:14px; font-family:Arial;\"> Id used in our previous step.</p> \n",
    "* UNET_CONFIGURATION <p style=\"font-size:14px; font-family:Arial;\"> String that identifies the requested U-Net configuration such as 2d, 3d_fullres, 3d_lowres, 3d_cascade_lowres. </p>\n",
    "* FOLD <p style=\"font-size:14px; font-family:Arial;\"> Specifies which fold of the 5-fold-cross-validation is trained.  <br><br>\n",
    "Additional details about model training are available <a href=\"https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md#model-training\"> here </a> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example command for training\n",
    "\n",
    "nnUNetv2_train 001 3d_fullres 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:12px; font-family:Arial;\">The trained models will be written to the nnUNet_results folder. Each training obtains an automatically generated output folder name:\n",
    "\n",
    "nnUNet_results/DatasetXXX_MYNAME/TRAINER_CLASS_NAME__PLANS_NAME__CONFIGURATION/FOLD</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the plot of different metrics during our training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Training metrics](training_metrics_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_hk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
